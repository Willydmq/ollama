# Ollama

Ver en "localhost:3000"

# La version actual de chatbot-ollama no descarga el modelo automaticamente
# Vas a tener que correr este comando cada vez que necesites un modelo nuevo:
# docker-compose exec ollama ollama pull llama2  

